moved in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
{'loss': 1.6934, 'grad_norm': 1.951101541519165, 'learning_rate': 1.9495155532891385e-05, 'epoch': 0.03}
{'loss': 0.9174, 'grad_norm': 0.0003629677230492234, 'learning_rate': 1.8985211626721063e-05, 'epoch': 0.05}      
{'loss': 0.7574, 'grad_norm': 2.601776599884033, 'learning_rate': 1.847526772055074e-05, 'epoch': 0.08}
{'loss': 0.5212, 'grad_norm': 6.801779270172119, 'learning_rate': 1.796532381438042e-05, 'epoch': 0.1}
{'loss': 0.8493, 'grad_norm': 71.06426239013672, 'learning_rate': 1.74553799082101e-05, 'epoch': 0.13}
{'loss': 0.6551, 'grad_norm': 684.3232421875, 'learning_rate': 1.6945436002039778e-05, 'epoch': 0.15}
{'loss': 0.5346, 'grad_norm': 47.71343231201172, 'learning_rate': 1.6435492095869456e-05, 'epoch': 0.18}
{'loss': 0.4011, 'grad_norm': 0.012843878008425236, 'learning_rate': 1.5925548189699134e-05, 'epoch': 0.2}        
{'loss': 0.2817, 'grad_norm': 0.02247069776058197, 'learning_rate': 1.5415604283528812e-05, 'epoch': 0.23}        
{'loss': 0.1927, 'grad_norm': 0.03881141170859337, 'learning_rate': 1.4905660377358491e-05, 'epoch': 0.25}        
{'loss': 0.3198, 'grad_norm': 0.05658990517258644, 'learning_rate': 1.439571647118817e-05, 'epoch': 0.28}         
{'loss': 0.3881, 'grad_norm': 293.3315734863281, 'learning_rate': 1.3885772565017849e-05, 'epoch': 0.31}          
{'loss': 0.4268, 'grad_norm': 0.012963482178747654, 'learning_rate': 1.3375828658847527e-05, 'epoch': 0.33}       
{'loss': 0.5425, 'grad_norm': 0.30877289175987244, 'learning_rate': 1.2865884752677207e-05, 'epoch': 0.36}        
{'loss': 0.3639, 'grad_norm': 0.0529005341231823, 'learning_rate': 1.2355940846506885e-05, 'epoch': 0.38}         
{'loss': 0.2764, 'grad_norm': 0.2475244104862213, 'learning_rate': 1.1845996940336564e-05, 'epoch': 0.41}         
{'loss': 0.4167, 'grad_norm': 0.09103849530220032, 'learning_rate': 1.1336053034166244e-05, 'epoch': 0.43}        
{'loss': 0.1937, 'grad_norm': 0.046687692403793335, 'learning_rate': 1.082610912799592e-05, 'epoch': 0.46}        
{'loss': 0.2423, 'grad_norm': 1.0428534746170044, 'learning_rate': 1.03161652218256e-05, 'epoch': 0.48}           
{'loss': 0.2756, 'grad_norm': 0.02580725960433483, 'learning_rate': 9.806221315655278e-06, 'epoch': 0.51}         
{'loss': 0.3261, 'grad_norm': 0.009671985171735287, 'learning_rate': 9.296277409484958e-06, 'epoch': 0.54}        
{'loss': 0.3155, 'grad_norm': 0.14861011505126953, 'learning_rate': 8.786333503314636e-06, 'epoch': 0.56}         
{'loss': 0.4029, 'grad_norm': 0.02539861761033535, 'learning_rate': 8.276389597144315e-06, 'epoch': 0.59}         
{'loss': 0.2961, 'grad_norm': 0.054358892142772675, 'learning_rate': 7.766445690973993e-06, 'epoch': 0.61}        
{'loss': 0.2321, 'grad_norm': 0.010327205993235111, 'learning_rate': 7.256501784803672e-06, 'epoch': 0.64}        
{'loss': 0.1595, 'grad_norm': 0.006675068289041519, 'learning_rate': 6.746557878633351e-06, 'epoch': 0.66}        
{'loss': 0.1834, 'grad_norm': 0.019081203266978264, 'learning_rate': 6.236613972463029e-06, 'epoch': 0.69}        
{'loss': 0.1076, 'grad_norm': 0.006273600272834301, 'learning_rate': 5.726670066292708e-06, 'epoch': 0.71}        
{'loss': 0.1769, 'grad_norm': 0.1648787558078766, 'learning_rate': 5.216726160122387e-06, 'epoch': 0.74}
{'loss': 0.1915, 'grad_norm': 0.038200754672288895, 'learning_rate': 4.706782253952066e-06, 'epoch': 0.76}        
{'loss': 0.1051, 'grad_norm': 0.05495331808924675, 'learning_rate': 4.196838347781744e-06, 'epoch': 0.79}
{'loss': 0.4151, 'grad_norm': 786.8807373046875, 'learning_rate': 3.6868944416114234e-06, 'epoch': 0.82}
{'loss': 0.2569, 'grad_norm': 42.394466400146484, 'learning_rate': 3.176950535441102e-06, 'epoch': 0.84}
{'loss': 0.1525, 'grad_norm': 0.01308039203286171, 'learning_rate': 2.66700662927078e-06, 'epoch': 0.87}
{'loss': 0.2047, 'grad_norm': 0.026566116139292717, 'learning_rate': 2.157062723100459e-06, 'epoch': 0.89}        
{'loss': 0.2022, 'grad_norm': 0.029728669673204422, 'learning_rate': 1.6471188169301378e-06, 'epoch': 0.92}       
{'loss': 0.1775, 'grad_norm': 0.03196798637509346, 'learning_rate': 1.1371749107598164e-06, 'epoch': 0.94}        
{'loss': 0.2338, 'grad_norm': 0.02075350470840931, 'learning_rate': 6.272310045894953e-07, 'epoch': 0.97}
{'loss': 0.0856, 'grad_norm': 0.023772304877638817, 'learning_rate': 1.1728709841917389e-07, 'epoch': 0.99}       
{'train_runtime': 1708.8702, 'train_samples_per_second': 4.59, 'train_steps_per_second': 2.295, 'train_loss': 0.3702847558828351, 'epoch': 1.0}